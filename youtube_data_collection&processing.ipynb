{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f2d710-ec96-43dd-b720-00b8aff9f7e5",
   "metadata": {},
   "source": [
    "# Youtube Data Collection and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c92d094-bc29-49ae-8e69-89e5560ffafd",
   "metadata": {},
   "source": [
    "### Collection with googleapiclient and requests libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209c313-150b-47b9-9a3f-64dd61443c76",
   "metadata": {},
   "source": [
    "First - build a dataframe with vidio ID, title, short description and category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca19a32-2118-4920-af74-bb9909b78f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "api_key = \"*******************************\"\n",
    "youtube_api = build('youtube','v3', developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753810f4-6b8f-44ba-ad59-466901d673dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initiate empty lists\n",
    "titles = []\n",
    "short_descriptions = []\n",
    "ids = []\n",
    "category = []\n",
    "## q- is the query you wand to search in youtube\n",
    "req = youtube_api.search().list(\n",
    "                            q='technical ted talk',\n",
    "                            order=\"relevance\", \n",
    "                            part='snippet', \n",
    "                            type='videos', \n",
    "                            maxResults = 50)\n",
    "res = req.execute()\n",
    "while(len(titles)<no_of_samples):\n",
    "    for i in range(len(res['items'])):\n",
    "        titles.append(res['items'][i]['snippet']['title'])\n",
    "        short_descriptions.append(\n",
    "              res['items'][i]['snippet']['description'])\n",
    "        try: \n",
    "            ids.append(res['items'][i]['id']['videoId'])\n",
    "        except:\n",
    "            ids.append('')\n",
    "        category.append('Ted_talk')\n",
    "            \n",
    "    if('nextPageToken' in res):\n",
    "        next_page_token = res['nextPageToken']\n",
    "        req = youtube_api.search().list(\n",
    "                                   q='flirting ted talk',\n",
    "                                   order=\"relevance\",\n",
    "                                   part='snippet', \n",
    "                                   type='videos', \n",
    "                                   maxResults = 50, \n",
    "                                   pageToken=next_page_token)\n",
    "        res = req.execute()\n",
    "    else:\n",
    "        break\n",
    "### Construct Dataset with the lists\n",
    "final_titles = titles\n",
    "final_descriptions = short_descriptions\n",
    "final_ids = ids\n",
    "### Build the dataframe\n",
    "data = pd.DataFrame({'Video Id': final_ids, 'Title': final_titles, 'Description': final_descriptions, 'Category': category})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef83f5a-f2c3-4580-bed6-56a804830681",
   "metadata": {},
   "source": [
    "Second - for each Video ID extract the full description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bf0c6-a83e-4017-a35c-f7d509040ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741a2d7-af60-47cf-8618-5cacd95aa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_description = []\n",
    "for idx in data['Video Id']:\n",
    "    r = requests.get(f'https://www.googleapis.com/youtube/v3/videos?  part=snippet&id={idx}&key={api_key}')\n",
    "    des = r.json()['items'][0]['snippet']['description']\n",
    "    full_description.append(des)\n",
    "data['full_description'] = full_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc280a0b-efbc-45aa-b082-988195b9814a",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0231af-446c-470c-bd7f-91358240680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_brackets(pred):\n",
    "    \"\"\"\n",
    "    This function removes brackets and the contant inside.\n",
    "    Input: pred - any text, here a summary.\n",
    "    Output: cleaned_pred - without brackets and contant inside. \n",
    "    \"\"\"\n",
    "    round_brackets = re.findall(r\"\\(([A-Za-z0-9_]+)\\)\", pred)\n",
    "    square_brackets = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\", pred)\n",
    "    cleaned_pred = pred\n",
    "    if round_brackets:\n",
    "        for match in round_brackets:\n",
    "            word_match = \"(\" + match + \")\"\n",
    "            cleaned_pred = cleaned_pred.replace(word_match,\"\")\n",
    "    if square_brackets:\n",
    "        for match in round_brackets:\n",
    "            word_match = \"(\" + match + \")\"\n",
    "            cleaned_pred = cleaned_pred.replace(word_match,\"\")\n",
    "    return cleaned_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8fa58-32b5-4685-94e8-ae800181d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_words(input):\n",
    "    \"\"\"\n",
    "    This function removes specific words.\n",
    "    Input: a string.\n",
    "    Output: clean_input - the string without the words. \n",
    "    \"\"\"\n",
    "    delete_word = [\"click\",\"|\"]\n",
    "    word_list = input.split(\" \")\n",
    "    clean_words = []\n",
    "    for orig_word in word_list:\n",
    "        if not orig_word in delete_word:\n",
    "            clean_words.append(orig_word)\n",
    "    clean_input = \" \".join(clean_words)\n",
    "    return clean_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cedf37-d0fe-40fa-bffc-7fb633a9d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_http(input):\n",
    "    \"\"\"\n",
    "    This function removes http.\n",
    "    Input: a string.\n",
    "    Output: clean_input - the string without the url. \n",
    "    \"\"\"\n",
    "    word_list = input.split(\" \")\n",
    "    clean_words = []\n",
    "    for orig_word in word_list:\n",
    "        if (\"http\" in orig_word) == False:\n",
    "            clean_words.append(orig_word)\n",
    "    clean_input = \" \".join(clean_words)\n",
    "    return clean_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbbb4c-b340-4588-a63b-dd9e4992f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hashtags(input):\n",
    "    \"\"\"\n",
    "    This function removes hastags.\n",
    "    Input: a string.\n",
    "    Output: clean_input - the string without the hastag. \n",
    "    \"\"\"\n",
    "    word_list = input.split(\" \")\n",
    "    clean_words = []\n",
    "    for word in word_list:\n",
    "        if word.startswith(\"#\") == False:\n",
    "            clean_words.append(word)\n",
    "    clean_input = \" \".join(clean_words)\n",
    "    return clean_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7410e-757b-44e9-b553-5963ef66a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_english(input):\n",
    "    \"\"\"\n",
    "    This function removes non-English words as well as emojis.\n",
    "    Input: a string.\n",
    "    Output: clean_input - the string without the non-English words. \n",
    "    \"\"\"\n",
    "    word_list = input.split(\" \")\n",
    "    clean_words = []\n",
    "    for word in word_list:\n",
    "        if word.isascii() == True:\n",
    "            clean_words.append(word)\n",
    "    clean_input = \" \".join(clean_words)\n",
    "    return clean_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3e138-38a8-44a6-8e84-27a9743fcf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note - make sure to insert your relevat words in \"delete_sent\" to delete sentances with these words. \n",
    "\n",
    "import re\n",
    "def clean_data(input_txt):\n",
    "    delete_sent = [\"subscribe\",\"watch more\",\"facebook\",\"instagram\",\"twitter\",\"tumblr\",\"newsletter\",\"website\",\"merch\",\"youtube\",\"google\",\"ebook\",\n",
    "             \"git-hub\",\"tutorial\",\"games\",\"gameplay\",\"coupon\",\"news\",\"read more\",\n",
    "             \"follow\", \"abc\",\"cbs\",\"msnbc\",\"business insider\",\"bnc\",\"cbc\",\"fox\",\"kcra\"]\n",
    "    delete_word = [\"click here\"]\n",
    "    list_input_txt = sent_tokenize(input_txt)\n",
    "    clean_list = []\n",
    "    for sen in list_input_txt:\n",
    "        if any(word.lower() in sen.lower() for word in delete_sent) == False:\n",
    "            clean_list.append(sen)    \n",
    "    cleaned_sentences = []\n",
    "    for sen in clean_list:\n",
    "        # else:\n",
    "        \"\"\"\n",
    "        1. remove specific words\n",
    "        2. remove non English words, emogi\n",
    "        3. remove URLs\n",
    "        4. remove #\n",
    "        5. remove brackets\n",
    "        6. remove objects that are not punctuation |\n",
    "        \"\"\"\n",
    "        sen = clean_brackets(sen)\n",
    "        sen = delete_words(sen)\n",
    "        sen = delete_http(sen)\n",
    "        sen = clean_hashtags(sen)\n",
    "        sen = clean_non_english(sen)\n",
    "        cleaned_sentences.append(sen)\n",
    "    cleaned_input = \" \".join(cleaned_sentences)\n",
    "    return cleaned_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d8cff-e9c1-41b3-aa24-e4d75b7561cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_data = data['Full Description'].apply(clean_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
